{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import transaction data and aggregate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This workflow will demonstrate how to connect SQLite database with python to import and aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Create scripts that will process the CSV files, insert data into table and use that data in next step for performing various aggregations on it. The columns in the CSV files are as follow:\n",
    "\n",
    "“transactionId”, // a unique transaction identifier <br />\n",
    "“user”, // a unique user identifier <br />\n",
    "“datetime”, // a timestamp in ms (javascript format) <br />\n",
    "“operation”, // a description of the transaction being charged <br />\n",
    "“quantity”, <br />\n",
    "“unitPrice” // the revenue of the transaction is quantity * unit_price <br />\n",
    "We have use SQLite as a databse so the test is self-contained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Result\n",
    "\n",
    "### Part 1: Create an import script\n",
    "\n",
    "In the first part, we will create a script that imports the transactions of the CSV files into an SQL table.\n",
    "\n",
    "- The script should accept the CSV filename.\n",
    "- It should put the information into the DB, in a table that collects all transactions.\n",
    "- All data from CSVs imported by the script will be placed in this same table.\n",
    "- It should handle duplicate rows (i.e. same CSV imported twice by mistake or update existing data by processing a new file).\n",
    "\n",
    "### Part 2: Create an aggregation script\n",
    "\n",
    "In the second part, we will create a program that reads from the SQL table from the previous part and aggregates data into two new DB tables that allow to get the following information:\n",
    "\n",
    "- Aggregated by user / day: Number of operations and revenue per User per Day\n",
    "- Aggregated by user / hour: Number of operations and revenue per User per Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "###### First, Import SQLite3 as a database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from csv import reader\n",
    "from csv import DictReader\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Second, create a Database object and connect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'hexonet.db'\n",
    "connection = sqlite3.connect(database)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cur = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('transactions_2020-08-02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the details about the data stored in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       transactionId     user       datetime    operation  quantity  unitPrice\n",
      "0              30000  user_57  1596351600956  OPERATION_4         6      47.89\n",
      "1              30001  user_81  1596351602450  OPERATION_9         3      79.23\n",
      "2              30002  user_33  1596351603777  OPERATION_8         9      69.88\n",
      "3              30003  user_37  1596351606674  OPERATION_9         4      62.63\n",
      "4              30004  user_24  1596351615957  OPERATION_0         5      81.53\n",
      "...              ...      ...            ...          ...       ...        ...\n",
      "24995          54994  user_18  1596437988089  OPERATION_9         1      83.06\n",
      "24996          54996  user_96  1596437989006  OPERATION_6         7      35.93\n",
      "24997          54997  user_20  1596437990091  OPERATION_7         6      19.13\n",
      "24998          54998  user_53  1596437995615  OPERATION_0         4      52.71\n",
      "24999          54999  user_18  1596437998268  OPERATION_1         2      90.36\n",
      "\n",
      "[25000 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   transactionId  25000 non-null  int64  \n",
      " 1   user           25000 non-null  object \n",
      " 2   datetime       25000 non-null  int64  \n",
      " 3   operation      25000 non-null  object \n",
      " 4   quantity       25000 non-null  int64  \n",
      " 5   unitPrice      25000 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 976.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create table named 'tran' to store the records fetched from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Created...\n"
     ]
    }
   ],
   "source": [
    "cur = connection.cursor()\n",
    "sql = '''\n",
    "CREATE TABLE tran(\n",
    "transactionId INT, \n",
    "user TEXT, \n",
    "datetime NUMERIC, \n",
    "operation TEXT, \n",
    "quantity INT, \n",
    "unitPrice NUMERIC,\n",
    "tranDate TEXT,\n",
    "fileName TEXT\n",
    ")'''\n",
    "cur.execute(sql)\n",
    "print('Table Created...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Open the CSV file, read the data and insert these records into tran table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records Inserted successfully........\n"
     ]
    }
   ],
   "source": [
    "with open('transactions_2020-08-01.csv', 'r') as read_obj:\n",
    "    csv_dict_reader = DictReader(read_obj)\n",
    "    for row in csv_dict_reader:\n",
    "        #s = row['datetime']\n",
    "        s = 1596330211174\n",
    "        date = int(s) / 1000.0\n",
    "        tranDate = datetime.datetime.fromtimestamp(date).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "       #print(row['transactionId'], row['user'],row['datetime'],row['operation'],row['quantity'],row['unitPrice'],tranDate,'transactions_2020-08-02.csv')\n",
    "        cur.execute(\"SELECT EXISTS(SELECT 1 FROM tran WHERE transactionId=? LIMIT 1)\", (row['transactionId'],))\n",
    "        record = cur.fetchone()\n",
    "        if record[0] == 1:\n",
    "              cur.execute(''' update tran set user = ?, datetime= ?, operation = ?, quantity = ?, unitPrice = ?, tranDate = ?, fileName = ? where transactionId = ?''', (row['user'],row['datetime'],row['operation'],row['quantity'],row['unitPrice'],tranDate,'transactions_2020-08-02.csv',row['transactionId']))\n",
    "              connection.commit()\n",
    "              print(\"Records updated in table\")\n",
    "        else:\n",
    "              cur.execute('''INSERT INTO tran values (?, ?, ?, ?, ?, ?, ?, ?) ''', ( row['transactionId'], row['user'],row['datetime'],row['operation'],row['quantity'],row['unitPrice'],tranDate,'transactions_2020-08-02.csv'))\n",
    "              connection.commit()\n",
    "        print(\"Records Inserted successfully........\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(45000,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"select count(*) from tran\")\n",
    "results = cur.fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create new table named 'Agg_User_Per_Day' to store 'Number of operations and revenue per User per Day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully........\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE Agg_User_Per_Day(\n",
    "date TEXT,\n",
    "user TEXT,\n",
    "No_of_Operations INTEGER,\n",
    "Revenue NUMERIC\n",
    ")'''\n",
    "cur.execute(sql)\n",
    "print(\"Table created successfully........\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Aggregate the data fetched from tran table and insert it into new table.\n",
    "This will perform following:\n",
    "- Aggregated by user / day: Number of operations and revenue per User per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "   select substr(tranDate,0,11),user,count(operation),sum(quantity*unitPrice)\n",
    "   from tran group by substr(tranDate,0,11),user;\n",
    "        '''\n",
    "cur.execute(query)\n",
    "results = cur.fetchall()\n",
    "#print(results)\n",
    "\n",
    "cur.executemany('INSERT INTO Agg_User_Per_Day VALUES (?,?,?,?);',results)\n",
    "#Commit your changes in the database\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fetch the aggregated data from Agg_User_Per_Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12428956.66,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT sum(Revenue) FROM Agg_User_Per_Day \")\n",
    "results = cur.fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create new table named 'Agg_User_Per_Hour' to store 'Number of operations and revenue per User per Hour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0xe9799e0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE Agg_User_Per_Hour(\n",
    "date TEXT,\n",
    "hour TEXT,\n",
    "user TEXT,\n",
    "No_of_Operations INTEGER,\n",
    "Revenue NUMERIC\n",
    ")'''\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Aggregate the data fetched from tran table and insert it into new table. This will perform following:\n",
    "- Aggregated by user / hour: Number of operations and revenue per User per Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "   select substr(tranDate,0,11),substr(tranDate,12,2)as hour,user,count(operation), sum(quantity*unitPrice)\n",
    "    from tran group by substr(tranDate,0,11),user , substr(tranDate,12,2) ;\n",
    "        '''\n",
    "cur.execute(query)\n",
    "results = cur.fetchall()\n",
    "#print(results)\n",
    "\n",
    "cur.executemany('INSERT INTO Agg_User_Per_Hour VALUES (?,?,?,?,?);',results)\n",
    "# Commit your changes in the database\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fetch the aggregated data from Agg_User_Per_Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12428956.65999999,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT sum(Revenue) FROM Agg_User_Per_Hour\")\n",
    "results = cur.fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Flaws in this workflow:\n",
    "\n",
    "1. Further, if we want to prevent same file to get insert multiple times in the database, then we can store the filename and it's upload date-time in separate column and put validation on it.\n",
    "2. We can utilize available data in more detailed format and generate various reports like:\n",
    "- Total revenue by each operation\n",
    "- No.of transactions per day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "We can analyse this data using various tools like node JS, Python, Tableau, Power BI etc. Additionally, We can visualize this data in Tableau or Power BI to make it easy to understand and presentale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
